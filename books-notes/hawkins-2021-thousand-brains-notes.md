## Notes from the book "A Thousand Brains: A New Theory of Intelligence"

In part 1, the book proposes a framework for understanding the neocortex (the
new brain).
The framework is called "the thousand brains theory of intelligence".
Part 2 discusses machine intelligence in the context of the thousand brains
theory, and part 3 is futuristic stuff (the future of humanity, interplanetary
species, etc).

### Part 1

The old brain (reptilian brain) controls the muscles, the new brain (neocortex)
has to send signals to the old brain to do anything.

The new brain wraps around the old.

The old brain has several different parts that are visually identifiable.
The neocortex looks the same everywhere.
When spread flat, it is about as wide as a dinner napkin and 2.5mm thick.
It has six layers.
The bottom layer is closest to the old brain and the top one is closest to the
skull.
Most neuron connections go between layers, but some go within a layer too.
There are dozens of different types of neurons.

The neocortex is split into cortical columns.
A column is a region approximately 1mm^2 wide that spans the whole depth of the
neocortex.
It consists of neurons that light up together in response to a sensory stimulus.
The brain has roughly 150K cortical columns.

Vernon Mountcastle wrote a very influential essay in the 1970s.
He proposed that the brain regions all run essentially the same algorithm, and
that the difference in functionality is due to what each region is connected to.
(For example, when a person is blind, the area of the neocortex that normally
receives input from the eyes can be repurposed to perform some other task.)
Mountcastle said that the fundamental unit of intelligence is the cortical
column, but couldn't explain how it works.
Hawkins believes that this essay is as important as Darwin's theory of
evolution.

Hawkins says that the brain is commonly described as an input/output system,
but this is not a very useful view of the brain.
The brain may receive some inputs, but the person won't act on them until months
or years down the road.
A more useful view is that the brain constantly builds and refines its model of
the world in response to its inputs.
Then, it constantly makes predictions about what we are about to see or hear.
That's why we notice when we see something unexpected, even though we weren't
consciously thinking about it right before seeing it.

Each neuron cell has these tentacle-like things to receive input, called
dendrites, and to send output, called axons.
The axon of a neuron may be connected to thousands of dendrites of other
neurons.
These connections are called synapses.

When two neurons communicate a lot, their synapse is strengthened.
If they don't communicate for a while, the synapse is weakened.
The brain also creates new synapses and destroys others; the connectivity is not
fixed.
This is how learning happens.

Hawkins's lab discovered how the brain recognizes sequences.
90% of the dendrites in the brain are distal (not close to their neuron) and 10%
are proximal.
The distal ones can't cause a neuron to spike.
So what do they do?
When they receive input they recognize, they create a dendrite spike, which
reaches the neuron and puts it in an excited state.
This is a prediction.
Excited neurons spike faster than non-excited neurons, which see the activity
around them (how?) and are inhibited.

Thus, the brain is lots more active when it is surprised than when it predicts
things correctly.

Reference frames are a central construct in the book.
You can imagine a reference frame as a 2D or a 3D map, with Cartesian axes
overlayed on top of it, so that the objects in the map have coordinates.
The brain uses reference frames to know where an object is in relation to other
objects.
Hawkins say that the brain constantly creates and processes reference frames,
in each cortical column.

Maps in the old brain:
In the hippocampus and the entorhinal cortex, there are place cells and grid
cells.
A place cell fires when we are in a particular place.
A grid cell fires as we move in a pattern, e.g., on equal intervals along a
straight line.
The old brain uses these cells to create a map of the world and know where our
body is in the world.

Hawkins claims that these circuits also exist in every cortical column, and the
neocortex creates thousands of maps of objects and their relative locations.
This is the basis of reference frames.

When you are at a location, you also need to know your orientation at that
location to predict what you are about to see.
The old brain does this with head-direction cells.

Hawkins says that a cortical column has something equivalent, which he calls
orientation cells.

Each column can be an object recognizer by creating reference frames.
But not all columns in the brain are object recognizers.
Hawkins says that the brain creates reference frames even for abstract concepts
such as democracy, and that thinking is a form of moving, from one concept to
another. \
(It gets a little fuzzy here.
Is he essentially saying that concepts are arranged in a graph, with edges 
between related concepts? That seems fairly obvious.
What else do reference frames for abstract concepts offer?) \
Hawkins believes that the brain contains the equivalent of place and grid cells
to create reference frames for abstract concepts.

The cortex has two vision systems, the where and what regions.
The where region knows where an object is relative to our body but not what it
is.
The what region knows what it is but not where.
Other senses are also split into two regions.
Fascinating.

The dominant theory of the brain is hierarchical recognition of objects.
Vision in the brain is like looking at a photograph.
The lower levels in the hierarchy (regions V1 and V2) recognize small features,
and the higher levels full objects.
But then why are V1 and V2 so large, and why do mice only have V1 for vision
and can still see fine?

Hawkins says that the hierarchy theory has lots of problems, but they have
surfaced gradually over time, not all at once, so it has been hard to
displace.
He also dislikes the "vision as a still photo" idea, and says that vision
includes movement; we see an object from various angles and recognize it.

Mountcastle also didn't believe in the hierarchical model.

Instead of a hierarchy, Hawkins proposes that each cortical column recognizes
full objects.
An object is recognized by many columns, possibly even thousands, and as we
perceive, columns message each other with their predictions, and a form of
voting happens where they all settle on one thing.
This scheme also has redundancy, in case some area of the brain is damaged.

Their software simulations suggest that each column recognizes hundreds of
complete objects.

Each column in V1 gets input only from a small part of the retina.
It recognizes a complete object by integrating its inputs over time, in the same
way that we learn a city by visiting its places gradually.

The binding problem: the brain gets input from many senses, in various cortical
areas, and the input is patchy and distorted.
How does the brain synthesize complete and uninterrupted perception from this
input?

The hierarchy of features theory solves the binding problem by saying that all
inputs consolidate their processing in one place in the brain responsible for
recognizing a particular object.
But the connections that we know of don't look neat like that, they spread
around the brain more irregularly.

The thousand-brains theory says that instead, columns vote to settle in one
answer about an object.
The voting is distributed.

He mentions split brain patients, and how their brain halves are independent,
and voting can't happen between the two halves of the brain.
But then why do these people still have one source of identity and perception?
He doesn't explain that.

The thousand brains theory predicts that a hierarchy is not needed to learn
individual objects.
It says that the brain uses a hierarchy to learn complex objects from simpler
ones.
This is a bit suspicious to me.
First, how does the brain know if something is an object, vs just a feature of
an object, to assign a different learning territory to each of these?
Second, Hawkins doesn't discuss whether a composite object is considered to be
simple (one column) or complex (many columns) in his theory.
For example, a tree has a trunk, branches, leaves.
Can a tree be learned by one column or many?
I'd guess one, but it is not obvious from the text.

The book explains at a high level how the brain represents and recognizes
objects, but doesn't say anything about learning.
How do we classify a thing as a new object?
How are reference frames precisely represented in the brain and how are they
created?
How do we update and refine our knowledge of things?

Presumably if you take two columns that recognize some common objects, they
won't recognize the exact same set of objects.
What does the overlap tell us, and generally, how is it decided which set of
objects is learned where?

Another aspect of learning that isn't discussed.
As we practice and become better at something, the knowledge moves from
"system 2" to "system 1"; it becomes muscle memory and we respond much faster.
Hawkins doesn't say how this happens in his theory.
Does the vote of the "muscle memory" columns matter more gradually, or is the
object even forgotten from the initial "system 2" columns, or is something else
completely going on?

### Part 2

Part 2 talks about the implications of his theory to AI.
In the intro, he mentions a talk he gave at Intel during the Palm Pilot days,
before browsers existed.
In the talk, he predicted that the future of computing is handheld devices, and
the talk was not well received.
The main objection was that people couldn't see what these devices would be used
for.
He then implies that, based on the smartphone world we live in today, he was
right.
But it is hard to imagine smartphones happening without the internet, so I don't
share his assessment that what is happening now was inevitable at the time when
he gave the talk.

He similarly claims that his vision for AI is inevitable, and that most current
experts don't see it.
It will be hard to convince people with this attitude IMO.

He talks about universal Turing machines, and how general-purpose computers came
to dominate special-purpose computers.
Then says that similarly, general-purpose AI will come to dominate the
specialized systems of today.
A general-purpose AI is flexible; it can learn any subject, like a human.
He lists four components as essential for general-purpose AI:

* Learning continuously, instead of training and then deploying.
* Learning through movement, instead of still photos.
* Learning many models of each thing, akin to how the brain creates many models
  in many columns.
* Using reference frames to represent knowledge.

Hawkins criticizes label classifiers because they tell us that something is a
cat but can't say why they think that.
This statement forgets the field of neural net interpretability, which has made
big strides in explaining why nets make their predictions.

Qualia: how the brain goes from input spikes to senses, e.g., knowing that a
color is green, or how a food tastes.

Hawkings says that feelings, such as fear and sorrow, are generated in the old
brain.
Therefore, when we create intelligent machines based on the principles of the
neocortex, they won't have feelings, but they will have consciousness.
It is morally OK to destroy such a machine, because it doesn't have feelings.
It won't care.

It is not obvious to me how true intelligence can exist without feelings.
For example, it could be that feelings emerge in an intelligent entity as an
emergent property of how its brain works. 

Goals and motivations come from the old brain, and the new brain is
dispassionate.
Hawkins suggests that a similar split will happen in intelligent machines.

Aside: how much can the old brain learn and what is the process of learning in
the old brain?

He mentions that when we create intelligent machines, we will eventually think
of new applications for them that we can't even fathom now. 
To support this statement, he says that the internet was first created to
transfer military and academic files, and today's applications were imagined
later.
This is not correct.
The internet was imagined by JCR Licklider and others way before it was created,
and the goal was human-computer symbiosis.
But when it was finally created, it took a long time to build up its
capabilities.

Kurzweil and others imagine a future where intelligent machines will create ever
more intelligent ones in an exponentially accelerating pace that leaves humans
far behind.
Hawkins counters this, because even if a brain is a million times faster,
learning requires building a model of the world by interacting with it, and that
process can't be sped up arbitrarily.

To speed up learning, an intelligent machine could coordinate with many previous
ones that learned pieces of knowledge by interacting with the world, and copy
over those pieces to its brain.
Hawkins likely believes that this isn't possible, because knowledge won't be as
neatly organized and separable in the machine brain.
Or he may believe that the machine won't do it, because it lacks motivation to
do so.
Goals and motivations are part of the old brain, and completely separate from
intelligence.
I don't know if I believe this.
For example, people's goals drive much of their decisions, and what knowledge
they choose to acquire or discover.

### Part 3

Uploading one's brain is more like a fork in the road, like having children,
instead of continuity of a single being.

Talks about estate planning for humanity, meaning that if we all go extinct,
how can we communicate to other intelligent species that we were here?
By sun blockers that create a pattern.
